# ğŸ–¼ï¸ Image Captioner

**Image Captioner** is a deep learning project that generates natural language captions for images using a combination of a ResNet-50 encoder and an LSTM decoder. Built with PyTorch and Gradio, this project demonstrates an end-to-end pipeline for vision-to-text generation.

---

## ğŸ§  Architecture

- **Encoder**: Pre-trained ResNet-50 CNN extracts visual features from input images.
- **Decoder**: LSTM-based sequence generator that produces text descriptions conditioned on visual features.
- **Vocabulary**: Custom vocabulary built from training captions with support for unknown words.

---

## ğŸš€ Features

- Convert any image into a meaningful caption.
- Gradio interface for easy web-based interaction.
- Pretrained model checkpoint loading and inference.

---

## ğŸ“ Directory Structure

```
.
â”œâ”€â”€ checkpoints/              # Model checkpoints (ignored in git)
â”‚   â””â”€â”€ final_model.pth
â”œâ”€â”€ vocab/
â”‚   â””â”€â”€ vocab.pkl             # Serialized vocabulary
â”œâ”€â”€ main.py                   # Gradio app entrypoint
â”œâ”€â”€ model.py                  # Encoder and decoder models
â”œâ”€â”€ utils.py                  # Preprocessing and helper functions
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## ğŸ› ï¸ Installation

```bash
git clone https://github.com/Yavanash/ImageCaptioner.git
cd ImageCaptioner
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

Make sure you have the required files:

- `checkpoints/final_model.pth` â€” Trained model weights
- `vocab/vocab.pkl` â€” Vocabulary file

> Note: `.pth` files are large and ignored in version control. You may need to download them separately.

---

## ğŸ“¸ Running the App

```bash
python main.py
```

This launches a Gradio interface at `http://localhost:7860` or a shared URL if enabled.

---

## ğŸ§ª Example

Upload an image through the Gradio UI and the model will return a caption like:

```
"A group of people riding horses through a field"
```

---

## âš™ï¸ Model Details

- Encoder: `ResNet-50` (pretrained on ImageNet)
- Decoder: `1-layer LSTM` with hidden size 512 and embedding size 256
- Sequence length capped at 25 tokens
- Vocabulary built from training corpus with `min_freq=5`

---

## ğŸ§¾ License

This project is open-sourced under the [MIT License](LICENSE).

---

## âœ¨ Acknowledgements

- [PyTorch](https://pytorch.org/)
- [Gradio](https://www.gradio.app/)
- [Image Captioning Research](https://cs.stanford.edu/people/karpathy/deepimagesent/)

---

## ğŸ“¬ Contact

Made with â¤ï¸ by [@Yavanash](https://github.com/Yavanash)
